"""
Graceful fallback mechanisms for AI Agent Backend.

This module provides fallback responses and mock data when external APIs
are unavailable or API keys are missing.
"""

import asyncio
import os
import random
from typing import Dict, List, Any, Optional, AsyncGenerator
from datetime import datetime, timedelta
import json
import logging

logger = logging.getLogger(__name__)


class FallbackService:
    """
    Provides fallback responses and mock data for external services.
    
    This service ensures the application continues to function even when
    external APIs are unavailable, providing realistic mock responses
    for demonstration and development purposes.
    """
    
    def __init__(self):
        self.demo_delay = float(os.getenv("DEMO_RESPONSE_DELAY", "1"))
    
    async def get_mock_ai_response(
        self, 
        messages: List[Dict[str, str]], 
        model_id: str,
        stream: bool = True
    ) -> AsyncGenerator[str, None]:
        """
        Generate mock AI responses for demo mode.
        
        Args:
            messages: Conversation messages
            model_id: AI model identifier
            stream: Whether to stream the response
            
        Yields:
            Mock response chunks
        """
        user_message = messages[-1].get("content", "") if messages else ""
        
        # Generate contextual mock response
        mock_response = self._generate_mock_response(user_message, model_id)
        
        if stream:
            # Stream response word by word
            words = mock_response.split()
            for i, word in enumerate(words):
                chunk = word + (" " if i < len(words) - 1 else "")
                yield chunk
                await asyncio.sleep(0.1)  # Simulate streaming delay
        else:
            await asyncio.sleep(self.demo_delay)
            yield mock_response
    
    def _generate_mock_response(self, user_message: str, model_id: str) -> str:
        """Generate contextual mock response based on user input."""
        user_lower = user_message.lower()
        
        # Crypto-related queries
        if any(word in user_lower for word in ["bitcoin", "crypto", "btc", "ethereum", "eth", "price"]):
            return self._get_crypto_mock_response(user_message, model_id)
        
        # Search-related queries
        elif any(word in user_lower for word in ["news", "latest", "current", "today", "search"]):
            return self._get_search_mock_response(user_message, model_id)
        
        # Technical queries
        elif any(word in user_lower for word in ["code", "programming", "python", "javascript", "api"]):
            return self._get_technical_mock_response(user_message, model_id)
        
        # General queries
        else:
            return self._get_general_mock_response(user_message, model_id)
    
    def _get_crypto_mock_response(self, user_message: str, model_id: str) -> str:
        """Generate mock response for crypto-related queries."""
        responses = [
            f"ðŸš¨ **Demo Mode Active** - Using mock crypto data\n\nBased on simulated market data, Bitcoin is currently trading around $45,000 with a 2.3% increase in the last 24 hours. Please note this is mock data for demonstration purposes. To get real-time crypto prices, please configure your Binance API keys in the .env file.\n\n*Response generated by {model_id} (Demo Mode)*",
            
            f"ðŸ“Š **Demo Mode** - Mock cryptocurrency analysis\n\nThe crypto market appears to be showing bullish sentiment with major altcoins following Bitcoin's upward trend. Ethereum is performing well at around $2,800. Remember, this is simulated data for demo purposes only.\n\nTo access real market data, add your Binance API credentials to the environment configuration.\n\n*Simulated response from {model_id}*",
            
            f"ðŸ’° **Demo Response** - Crypto market overview\n\nCurrent mock market conditions show:\n- Bitcoin: ~$45,000 (+2.3%)\n- Ethereum: ~$2,800 (+1.8%)\n- Market Cap: ~$1.2T\n\nâš ï¸ This is demonstration data only. Configure Binance API keys for real-time market information.\n\n*Demo mode - {model_id}*"
        ]
        return random.choice(responses)
    
    def _get_search_mock_response(self, user_message: str, model_id: str) -> str:
        """Generate mock response for search-related queries."""
        responses = [
            f"ðŸ” **Demo Mode** - Mock search results\n\nI would normally search the web for current information about your query, but I'm currently running in demo mode. To enable real web search capabilities, please configure your SerpAPI or Brave Search API keys in the .env file.\n\nFor demonstration, here's what I might find: Recent developments in AI and technology continue to evolve rapidly, with new breakthroughs announced regularly.\n\n*Mock response from {model_id}*",
            
            f"ðŸ“° **Demo Search** - Simulated web results\n\nIn normal operation, I would fetch the latest news and information from the web. Currently running in demo mode with mock data.\n\nTo access real-time search results, add your search API credentials (SerpAPI or Brave Search) to the environment configuration.\n\n*Demonstration response - {model_id}*",
            
            f"ðŸŒ **Mock Web Search** - Demo mode active\n\nI'm simulating a web search for your query. In production mode with proper API keys, I would provide current, accurate information from reliable sources.\n\nTo enable live search: Configure SERP_API_KEY or BRAVE_SEARCH_API_KEY in your .env file.\n\n*Demo mode response from {model_id}*"
        ]
        return random.choice(responses)
    
    def _get_technical_mock_response(self, user_message: str, model_id: str) -> str:
        """Generate mock response for technical queries."""
        responses = [
            f"ðŸ’» **Demo Mode** - Technical assistance\n\nI can help with programming and technical questions even in demo mode! However, for the most up-to-date information and code examples, I would normally search current documentation and resources.\n\nFeel free to ask specific technical questions - I can provide general programming guidance using my training data.\n\n*Response from {model_id} (Demo Mode)*",
            
            f"ðŸ”§ **Technical Support** - Demo mode active\n\nI'm ready to help with your technical questions! While running in demo mode, I can still provide programming assistance, code examples, and technical explanations based on my training.\n\nFor the latest documentation and real-time technical resources, configure your search API keys.\n\n*Demo response - {model_id}*",
            
            f"âš¡ **Code Assistant** - Demo mode\n\nI can assist with programming questions, code review, and technical problem-solving even in demo mode. My responses are based on training data rather than real-time searches.\n\nWhat specific technical challenge can I help you with?\n\n*{model_id} in demo mode*"
        ]
        return random.choice(responses)
    
    def _get_general_mock_response(self, user_message: str, model_id: str) -> str:
        """Generate mock response for general queries."""
        responses = [
            f"ðŸŽ­ **Demo Mode Active**\n\nI'm currently running in demonstration mode because API keys haven't been configured. I can still have conversations and provide helpful information based on my training data!\n\nTo unlock full capabilities including real-time search, crypto data, and access to multiple AI models, please configure the appropriate API keys in your .env file.\n\nHow can I help you today?\n\n*Demo response from {model_id}*",
            
            f"ðŸ‘‹ **Hello from Demo Mode!**\n\nI'm operating in demonstration mode with mock responses. While I can't access real-time data or external APIs right now, I'm still here to help with questions and conversations!\n\nTo enable full functionality, add your API keys to the environment configuration.\n\nWhat would you like to discuss?\n\n*{model_id} (Demo Mode)*",
            
            f"ðŸ¤– **AI Assistant** - Demo mode\n\nI'm ready to help! Currently running in demo mode, which means I'm using simulated responses for external data sources. I can still provide assistance with general questions and conversations.\n\nFor full capabilities, configure your API keys in the .env file.\n\n*Demonstration response from {model_id}*"
        ]
        return random.choice(responses)
    
    async def get_mock_search_results(self, query: str, result_type: str = "web") -> List[Dict[str, Any]]:
        """
        Generate mock search results for demo mode.
        
        Args:
            query: Search query
            result_type: Type of search ("web" or "news")
            
        Returns:
            List of mock search results
        """
        await asyncio.sleep(self.demo_delay)
        
        if result_type == "news":
            return [
                {
                    "title": f"Mock News: Latest developments in {query}",
                    "description": "This is a mock news result for demonstration purposes. Configure SerpAPI or Brave Search for real news.",
                    "url": "https://example.com/mock-news-1",
                    "published": (datetime.now() - timedelta(hours=2)).isoformat(),
                    "source": "Demo News Source",
                    "type": "news"
                },
                {
                    "title": f"Breaking: {query} updates from demo mode",
                    "description": "Another mock news result. Real news requires proper API configuration.",
                    "url": "https://example.com/mock-news-2",
                    "published": (datetime.now() - timedelta(hours=5)).isoformat(),
                    "source": "Mock News Network",
                    "type": "news"
                }
            ]
        else:
            return [
                {
                    "title": f"Mock Search Result for '{query}'",
                    "description": "This is a demonstration search result. Configure search API keys for real web search capabilities.",
                    "url": "https://example.com/mock-result-1",
                    "type": "web"
                },
                {
                    "title": f"Demo: Information about {query}",
                    "description": "Another mock search result for demo purposes. Add SerpAPI or Brave Search keys to .env for real results.",
                    "url": "https://example.com/mock-result-2",
                    "type": "web"
                },
                {
                    "title": f"Sample Result: {query} resources",
                    "description": "Mock search result #3. Enable real search by configuring your API keys.",
                    "url": "https://example.com/mock-result-3",
                    "type": "web"
                }
            ]
    
    async def get_mock_crypto_data(self, symbol: Optional[str] = None) -> Dict[str, Any]:
        """
        Generate mock cryptocurrency data for demo mode.
        
        Args:
            symbol: Cryptocurrency symbol (optional)
            
        Returns:
            Mock crypto market data
        """
        await asyncio.sleep(self.demo_delay)
        
        if symbol:
            # Mock data for specific symbol
            mock_price = random.uniform(100, 50000)
            mock_change = random.uniform(-10, 10)
            
            return {
                "symbol": symbol.upper(),
                "price": round(mock_price, 2),
                "change_24h": round(mock_change, 2),
                "volume_24h": random.randint(1000000, 10000000),
                "market_cap": random.randint(1000000000, 100000000000),
                "last_updated": datetime.now().isoformat(),
                "demo_mode": True,
                "message": "This is mock data for demonstration. Configure Binance API for real market data."
            }
        else:
            # Mock market overview
            return {
                "market_overview": {
                    "total_market_cap": 1200000000000,
                    "total_volume_24h": 45000000000,
                    "bitcoin_dominance": 42.5,
                    "active_cryptocurrencies": 2500
                },
                "top_cryptocurrencies": [
                    {"symbol": "BTC", "price": 45000, "change_24h": 2.3},
                    {"symbol": "ETH", "price": 2800, "change_24h": 1.8},
                    {"symbol": "BNB", "price": 320, "change_24h": -0.5},
                    {"symbol": "ADA", "price": 0.85, "change_24h": 3.2},
                    {"symbol": "SOL", "price": 95, "change_24h": 4.1}
                ],
                "demo_mode": True,
                "message": "Mock cryptocurrency data for demonstration purposes."
            }
    
    def get_mock_model_list(self) -> List[Dict[str, Any]]:
        """
        Generate mock AI model list for demo mode.
        
        Returns:
            List of mock AI models
        """
        return [
            {
                "id": "demo-gpt-4",
                "name": "GPT-4 (Demo)",
                "provider": "openai",
                "description": "Mock GPT-4 model for demonstration",
                "available": True,
                "demo_mode": True
            },
            {
                "id": "demo-claude-3",
                "name": "Claude 3 (Demo)",
                "provider": "anthropic",
                "description": "Mock Claude 3 model for demonstration",
                "available": True,
                "demo_mode": True
            },
            {
                "id": "demo-llama-70b",
                "name": "Llama 3.1 70B (Demo)",
                "provider": "groq",
                "description": "Mock Llama model for demonstration",
                "available": True,
                "demo_mode": True
            }
        ]


# Global fallback service instance
fallback_service = FallbackService()


async def get_fallback_ai_response(
    messages: List[Dict[str, str]], 
    model_id: str,
    stream: bool = True
) -> AsyncGenerator[str, None]:
    """Get fallback AI response for demo mode."""
    async for chunk in fallback_service.get_mock_ai_response(messages, model_id, stream):
        yield chunk


async def get_fallback_search_results(query: str, result_type: str = "web") -> List[Dict[str, Any]]:
    """Get fallback search results for demo mode."""
    return await fallback_service.get_mock_search_results(query, result_type)


async def get_fallback_crypto_data(symbol: Optional[str] = None) -> Dict[str, Any]:
    """Get fallback crypto data for demo mode."""
    return await fallback_service.get_mock_crypto_data(symbol)


def get_fallback_model_list() -> List[Dict[str, Any]]:
    """Get fallback model list for demo mode."""
    return fallback_service.get_mock_model_list()